using CSV
using DataFrames
using Plots
using Statistics
using MLJ
using StableRNGs
using Random
using CSV
using DataFrames

#daiiiiiiiiiiiii
function load_lookup_table(file_path::String)
    data = CSV.File(file_path)
    lookup_table = Dict{String, Float64}()
    
    for row in data
        key = string(row.features)  # Assicurati che 'features' sia la colonna corretta
        key = lpad(key, 6, '0')     # Assicurati che la chiave sia lunga 6 caratteri
        lookup_table[key] = row.loss  # Assicurati che 'loss' sia la colonna corretta
    end

    #println("First 5 keys in lookup table: ", collect(keys(lookup_table))[1:5])  # FIX QUI

    return lookup_table
end


function get_fitness_lookup(ind::Vector{Bool}, lookup_table::Dict{String, Float64})
    key = join(map(x -> x ? "1" : "0", ind))
    key = lpad(key, 6, '0')

    
    if key == "000000"
        #println("Key '000000' √® una configurazione vuota: penalit√†")
        return 9999.0
    end

    if haskey(lookup_table, key)
        return lookup_table[key]
    else
        #println("Key not found in lookup table: ", key)
        return 9999.0
    end
end


function get_population_fitness(model, X, y, population; lookup_table, rng=Random.GLOBAL_RNG)
    fitness_scores = zeros(size(population, 1))  # Inizializza un array per i punteggi di fitness
    
    for i in 1:size(population, 1)
        ind = population[i, :]  # Estrai un singolo individuo (una riga della matrice)
        # Assicurati che ind sia un singolo Vector{Bool}
        if typeof(ind) == Vector{Vector{Bool}}
            ind = ind[1]  # Estrai il vero individuo se √® un Vector{Vector{Bool}}
        end
        #println("Current individual: ", ind)  # Debug per stampare l'individuo
        fitness_scores[i] = get_fitness_lookup(collect(ind), lookup_table)  # Converti in Vector{Bool}
    end

    #println("Fitness scores (first 5): ", fitness_scores[1:min(5, end)])  # Debug per vedere solo i primi 5
    return fitness_scores
end







#Inizializzazione e Utilit√†
# Inizializzazione popolazione come Matrix{Bool}
function initialize_population(n_pop, n_items)
    return Matrix{Bool}(undef, n_pop, n_items) .| rand(Bool, n_pop, n_items)  # Assicurati che la popolazione sia una matrice
end



function get_columns(X, ind)
    indices = [i for (i,j) in enumerate(ind) if j==1]
    return X[:, indices]
end



#Fitness e Valutazione
function get_fitness1(model, Xsub, y; penalty_weight=0.01, num_features=0, rng=Random.GLOBAL_RNG)
    mach = machine(model, Xsub, y)
    train, test = partition(eachindex(y), 0.8, rng=rng)
    fit!(mach, rows=train, verbosity=0)
    yhat = predict(mach, Xsub[test, :])
    rmse_val = rmse(yhat, y[test])
    penalty = penalty_weight * num_features
    return rmse_val + penalty
end

function get_population_fitness1(model, X, y, population; rng=Random.GLOBAL_RNG)
    fitness_scores = zeros(size(population, 1))
    for i in 1:size(population, 1)
        ind = population[i, :]
        X_sub = get_columns(X, ind)
        fitness_scores[i] = get_fitness(model, X_sub, y; penalty_weight=0.01, num_features=sum(ind), rng=rng)

    end
    return fitness_scores
end

#Selezione

function tournament_selection(fitness::Vector{Float64}, num_parents::Int64, tournament_size::Int64)
    parents = Vector{Int}(undef, num_parents)
    for i in 1:num_parents
        candidates = randperm(length(fitness))[1:tournament_size]
        best_index = argmin(fitness[candidates])
        parents[i] = candidates[best_index]
    end
    return parents
end

function roulette_wheel_selection(fitness_values::Vector{Float64}, num_parents::Int64)
    num_parents = min(num_parents, length(fitness_values))
    total_fitness = sum(fitness_values)
    probabilities = fitness_values ./ total_fitness
    cumulative_probabilities = cumsum(probabilities)
    sub_set = Int[]
    
    while length(sub_set) < num_parents
        r = rand()
        for (i, cp) in enumerate(cumulative_probabilities)
            if r <= cp && !(i in sub_set)
                push!(sub_set, i)
                break
            end
        end
    end
    return sub_set
end

function elitism(fitness::Vector{Float64}, num_parents::Int64)
    best_indices = sortperm(fitness, rev=false)[1:num_parents]
    return best_indices
end


#Crossover e Mutation

function two_point_crossover(population::Matrix{Bool})
    num_individuals, num_genes = size(population)
    offspring = Matrix{Bool}(undef, num_individuals, num_genes)  # Inizializza come Matrix{Bool}
    offspring .= population
    shuffle_idx = shuffle(1:num_individuals)

    for i in 1:2:(num_individuals-1)
        parent1, parent2 = shuffle_idx[i], shuffle_idx[i+1]
        point1, point2 = sort(rand(1:num_genes, 2))
        offspring[parent1, point1:point2], offspring[parent2, point1:point2] =
            population[parent2, point1:point2], population[parent1, point1:point2]
    end
    return offspring
end

function mutation_max_n_genes!(curr_pop::Matrix{Bool}, mutation_probability::Float64, n::Int64)
    num_rows, num_cols = size(curr_pop)
    for i in 1:num_rows
        gene_to_mutate = randperm(num_cols)[1:n]
        for j in eachindex(gene_to_mutate)
            if rand() < mutation_probability
                curr_pop[i, gene_to_mutate[j]] = !curr_pop[i, gene_to_mutate[j]]
            end
        end
    end
end


#Metriche di distanza
function hamming_distance(x::Vector{Bool}, y::Vector{Bool})
    return sum(x .‚â† y)  # Conta i bit diversi
end

function mean_hamming_distance(population::Matrix{Bool})
    n = size(population, 1)  # Numero di individui
    total_distance = 0
    count = 0

    for i in 1:n, j in i+1:n  # Confronta ogni coppia una sola volta
        total_distance += hamming_distance(population[i, :], population[j, :])
        count += 1
    end

    return total_distance / count  # Media della distanza
end

#Visualizzazione

function plot_fitness_evolution(mean_fitness::Vector{Float64}, max_fitness::Vector{Float64}, min_fitness::Vector{Float64})
    # Creazione del grafico
    p = plot(1:length(mean_fitness), mean_fitness, label="Mean", lw=2, color=:blue, linestyle=:solid)  # Media
    plot!(p, 1:length(max_fitness), max_fitness, label="Maximum", lw=2, color=:green, linestyle=:solid)  # Massimo
    plot!(p, 1:length(min_fitness), min_fitness, label="Minimum", lw=2, color=:red, linestyle=:solid)  # Minimo
    xlabel!(p, "Iteration")  # Etichetta asse x
    ylabel!(p, "Fitness")  # Etichetta asse y
    title!(p, "Fitness Evolution")  # Titolo
    display(p)  # Mostra il grafico finale
end
function plot_hamming_distance(distance::Vector{Float64})
    p = plot(1:length(distance), distance, label="Distance", lw=2, color=:black, linestyle=:solid)  # Distance
    xlabel!(p, "Iteration")  # Etichetta asse x
    ylabel!(p, "Distance")  # Etichetta asse y
    title!(p, "Distance Evolution")  # Titolo
    display(p)  # Mostra il grafico finale
end




# Caricamento dati
data = CSV.read("C:/Users/giovy/Desktop/scopiazziamo/copia3/dataset.txt", DataFrame; header=0)
y, X = unpack(data, ==(:Column102))
lookup_table = load_lookup_table("C:/Users/giovy/Desktop/scopiazziamo/ensemble_feature.csv")



# Costanti e parametri
myRNG = 123
N_POP = 100
N_ITEMS = 6
MAX_RMSE = 0.124
PROB_MUTATION = 0.8
GENES_MUTATED = 4
MAX_ITER = 200  # o quanto vuoi


# Inizializzazione variabili globali
global mean_fitness = Float64[]
global max_fitness = Float64[]
global min_fitness = Float64[]
global distance = Float64[]
global curr_pop = initialize_population(N_POP, N_ITEMS)  # Assicurati che ritorni una matrice di tipo Matrix{Bool}

global iter = 0
global best_features_selection = []

# Caricamento modello
LinearRegressor = @load LinearRegressor pkg=MLJLinearModels verbosity=0
model = LinearRegressor()
global best_rmse = Inf
# Evoluzione
while best_rmse ‚â• MAX_RMSE && iter < MAX_ITER
    global iter += 1
    global curr_pop
    #cambiato questo
    fitness = get_population_fitness(model, X, y, curr_pop; lookup_table=lookup_table)

    global best_rmse = minimum(fitness)
    #println("Iteration n' $iter - Best RMSE: $best_rmse")

    # Calcola solo tra individui validi
    valid_fitness_indices = findall(f -> f < 9999.0, fitness)

    if !isempty(valid_fitness_indices)
        best_idx = valid_fitness_indices[argmin(fitness[valid_fitness_indices])]
        global best_rmse = fitness[best_idx]
        global best_features_selection = curr_pop[best_idx, :]
    else
        println("‚ö†Ô∏è Nessun individuo valido nella generazione $iter")
    end


    # Se ha trovato un individuo valido con RMSE sotto la soglia, ferma il ciclo
    if best_rmse < MAX_RMSE
        break
    end


    """if best_features_selection !== nothing
        println("Best RMSE: ", best_rmse)
        println("Best individual: ", join(map(x -> x ? "1" : "0", best_features_selection)))
    else
        println("No valid individual found in lookup table.")
    end"""

    # Selezione dei genitori
    crossovering_parents = tournament_selection(fitness, Int64(round(N_POP / 10 * 8)), 10)
    selected_parents = curr_pop[crossovering_parents, :]  # Assicurati che sia una matrice

    # Conversione in Matrix{Bool}
    selected_parents = Matrix{Bool}(selected_parents)

    # Esegui crossover
    offspring = two_point_crossover(selected_parents)
    offspring = Matrix{Bool}(offspring)  # Assicurati che l'output del crossover sia una Matrix{Bool}

    # Concatenazione della popolazione
    curr_pop = vcat(curr_pop, offspring)

    # Mutazione
    curr_pop = Matrix{Bool}(curr_pop)  # Forza il tipo corretto
    mutation_max_n_genes!(curr_pop, PROB_MUTATION, GENES_MUTATED)
    



    # Selezione elitista
    fitness = get_population_fitness(model, X, y, curr_pop; lookup_table=lookup_table)
   
    best_candidates_indices = elitism(fitness, N_POP)
    curr_pop = curr_pop[best_candidates_indices, :]  # Seleziona solo i migliori



    push!(mean_fitness, mean(fitness))
    push!(max_fitness, maximum(fitness))
    push!(min_fitness, minimum(fitness))
    # Calcola la distanza di Hamming media
    push!(distance, mean_hamming_distance(Matrix(curr_pop)))

end

# ... [TUTTO IL TUO CODICE PRIMA √à INVARIATO] ...


# Output finale
plot_fitness_evolution(mean_fitness, max_fitness, min_fitness)
plot_hamming_distance(distance)

best_features_selection = Vector{Bool}(best_features_selection)
best_fitness = get_fitness_lookup(collect(best_features_selection), lookup_table)
println("Best RMSE: ", best_fitness)

# üîù STAMPA DELLE 5 MIGLIORI SOLUZIONI FINALI
final_fitness = get_population_fitness(model, X, y, curr_pop; lookup_table=lookup_table)
sorted_indices = sortperm(final_fitness)[1:5]

println("Le 5 migliori soluzioni finali:")
for i in sorted_indices
    individual = curr_pop[i, :]
    rmse = final_fitness[i]
    bitstring = join(map(x -> x ? "1" : "0", individual))
    println(" - RMSE: ", round(rmse, digits=6), " | Individuale: ", bitstring)
end
